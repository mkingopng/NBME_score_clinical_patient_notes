"""

"""
# The following is necessary if you want to use the fast tokenizer for deberta v2 or v3

import os
from datetime import datetime
from collections import Counter
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional
from itertools import chain
from functools import partial
from ast import literal_eval
import shutil
import wandb
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import precision_recall_fscore_support

import torch


import pandas as pd
import numpy as np

import plotly.express as px
import plotly.offline as pyo

from datasets import load_dataset
from datasets import Dataset


from HUGGINGFACE import *

import transformers
from transformers.modeling_outputs import TokenClassifierOutput
import os
from datetime import datetime
from collections import Counter
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional
from itertools import chain
from functools import partial
from ast import literal_eval

import torch
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import precision_recall_fscore_support

from datasets import load_dataset, Dataset

from transformers import (
    AutoConfig,
    AutoTokenizer,
    DataCollatorForTokenClassification,
    HfArgumentParser,
    Trainer,
    TrainingArguments,
    set_seed,
    logging,
)

from transformers.modeling_outputs import TokenClassifierOutput

# enviroment
logging.set_verbosity(logging.WARNING)
TOKENIZERS_PARALLELISM = True
HF_DATASETS_OFFLINE = 1
TRANSFORMERS_OFFLINE = 1
DEBUG = False

# directories & files
tokenizer_dir = 'deberta-v2-3-fast-tokenizer'
convert_file = os.path.join(tokenizer_dir, "convert_slow_tokenizer.py")
deberta_v2 = DEBERTA_V2
DebertaV2TokenizerFast = 'deberta-v2-3-fast-tokenizer/tokenization_deberta_v2_fast'

model = DEBERTA_V3
all_models = [model] * 5

@dataclass
class ModelArguments:
    """
    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.
    """

    model_name_or_path: str = field(
        metadata={"help": "Path to pretrained model or model identifier from huggingface.co/models"}
    )


@dataclass
class DataTrainingArguments:
    """
    Arguments pertaining to what data we are going to input our model for training and eval.
    """
    k_folds: int = field(
        default=5,
        metadata={"help": "How many folds for kfold validation"}
    )
    val_split_percentage: Optional[float] = field(
        default=None,
        metadata={"help": "How much of the data to use for doing train_test_split. If None, already assumes "
                          "there are separate traiin and validation files"},
    )
    preprocessing_num_workers: Optional[int] = field(
        default=None,
        metadata={"help": "The number of processes to use for the preprocessing."},
    )
    max_seq_length: int = field(
        default=None,
        metadata={
            "help": "The maximum total input sequence length after tokenization. If set, sequences longer "
                    "than this will be truncated, sequences shorter will be padded."
        },
    )
    pad_to_max_length: bool = field(
        default=False,
        metadata={
            "help": "Whether to pad all samples to model maximum sentence length. "
                    "If False, will pad the samples dynamically when batching to the maximum length in the batch. More "
                    "efficient on GPU but very bad for TPU."
        },
    )
    max_train_samples: Optional[int] = field(
        default=None,
        metadata={
            "help": "For debugging purposes or quicker training, truncate the number of training examples to this "
                    "value if set."
        },
    )
    max_eval_samples: Optional[int] = field(
        default=None,
        metadata={
            "help": "For debugging purposes or quicker training, truncate the number of evaluation examples to this "
                    "value if set."
        },
    )
    max_predict_samples: Optional[int] = field(
        default=None,
        metadata={
            "help": "For debugging purposes or quicker training, truncate the number of prediction examples to this "
                    "value if set."
        },
    )
    label_all_tokens: bool = field(
        default=False,
        metadata={
            "help": "Whether to put the label for one word on all tokens of generated by that word or just on the "
                    "one (in which case the other tokens will have a padding index)."
        },
    )
    return_entity_level_metrics: bool = field(
        default=False,
        metadata={"help": "Whether to return all the entity levels during evaluation or just the overall ones."},
    )


model_args = ModelArguments(model_name_or_path=all_models[0])

data_args = DataTrainingArguments(
    k_folds=5,
    max_seq_length=512,
    pad_to_max_length=False,
    preprocessing_num_workers=4,
)

training_args = TrainingArguments(
    output_dir="model",
    do_train=True,
    do_eval=True,
    do_predict=True,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    gradient_accumulation_steps=2,
    learning_rate=2e-5,
    weight_decay=0.01,
    num_train_epochs=5,
    lr_scheduler_type="linear",
    warmup_ratio=0.1,
    logging_steps=75,
    evaluation_strategy="epoch",
    save_strategy="no",
    seed=18,
    fp16=False,
    report_to="wandb",
    group_by_length=True,
)

set_seed(training_args.seed)

data_dir = "data"
feats_df = pd.read_csv(os.path.join(data_dir, "features.csv"))
notes_df = pd.read_csv(os.path.join(data_dir, "patient_notes.csv"))
train_df = pd.read_csv(os.path.join(data_dir, "train.csv"))
