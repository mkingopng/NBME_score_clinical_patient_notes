import os

TRANSFORMERS = '/home/noone/documents/github/transformers'

TOKENIZERS = '/home/noone/documents/github/tokenizers'

DATASETS = '/home/noone/documents/github/datasets'

MODELS = os.path.join(TRANSFORMERS, 'src/transformers/models')

DEBERTA_V2 = os.path.join(MODELS, 'deberta_v2')

DEBERTA_V3 = os.path.join(MODELS, 'deberta-v3-base')

ENCODER_DECODER = os.path.join(MODELS, 'encoder_decoder')

HUGGINGFACE_HUB = '/home/noone/documents/github/huggingface_hub'


"""
Huggingface Repos Cloned:
    - transformers
    - tokenizers
    = optimum
    - datasets
    - huggingface_hub
    - accelerate
        
    - notebooks
    - blog
    - huggingface sagemaker snowflake example
    - education toolkit
    - evaluate
    - knockknock
    - neuralcoref
    - mongoku
    - data-measurements-tool
    - neural compressor
    - allennlp
    - pytorch-openai-transformer-lm
    - pytorch pretrained bigGAN
    - awesome NLP discussion papers
    - torchMoji
    - naacl_transfer_learning_tutorial
    - 
"""